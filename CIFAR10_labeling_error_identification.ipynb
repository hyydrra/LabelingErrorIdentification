{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OwnR2juv_U4S"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet\n",
        "!pip install cleanlab"
      ],
      "metadata": {
        "id": "KgeJ952_vncj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import cifar10, cifar100\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "eWKWCK6RrfT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWILUdR9cub7"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, Activation, BatchNormalization, Flatten\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "import efficientnet.keras as enet\n",
        "\n",
        "\n",
        "# Swish defination\n",
        "from keras.backend import sigmoid\n",
        "\n",
        "class SwishActivation(Activation):\n",
        "    \n",
        "    def __init__(self, activation, **kwargs):\n",
        "        super(SwishActivation, self).__init__(activation, **kwargs)\n",
        "        self.__name__ = 'swish_act'\n",
        "\n",
        "def swish_act(x, beta = 1):\n",
        "    return (x * sigmoid(beta * x))\n",
        "\n",
        "\n",
        "from keras.layers import Activation\n",
        "tf.keras.saving.get_custom_objects().update({'swish_act': SwishActivation(swish_act)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUGkuUVGhBsC"
      },
      "outputs": [],
      "source": [
        "# Load the CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# # Select a random image from the training set\n",
        "# image_index = 2\n",
        "# image = train_images[image_index]\n",
        "\n",
        "# # Display the image\n",
        "# plt.imshow(image)\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gnerating OOS images"
      ],
      "metadata": {
        "id": "10xl9cS2_eT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding noise to freqquency domain"
      ],
      "metadata": {
        "id": "yTKbRT2K_QOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import cv2\n",
        "\n",
        "# # load the image\n",
        "# img = image\n",
        "\n",
        "# # apply FFT to the image\n",
        "# f = np.fft.fft2(img)\n",
        "\n",
        "# # shift the zero frequency component to the center of the spectrum\n",
        "# fshift = np.fft.fftshift(f) *4\n",
        "\n",
        "# # add bias to the zero frequency component\n",
        "# rows, cols,_ = img.shape\n",
        "# crow, ccol = rows//2, cols//2\n",
        "\n",
        "# fshift[crow, ccol] = fshift[crow, ccol]   # add a bias of 1000\n",
        "\n",
        "# # shift the zero frequency component back to the corner of the spectrum\n",
        "# f_ishift = np.fft.ifftshift(fshift)\n",
        "\n",
        "# # apply inverse FFT to get the image back\n",
        "# img_back = np.fft.ifft2(f_ishift)\n",
        "# img_back = np.abs(img_back)  # take the absolute value\n",
        "\n",
        "# # convert the image back to 8-bit unsigned integer format\n",
        "# img_back = np.uint8(img_back)\n",
        "\n",
        "# # show the original and processed images\n",
        "# plt.imshow(image)\n",
        "# plt.show()\n",
        "# plt.imshow(img_back)\n",
        "# plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "WVGZxvavhNt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training AE oncifar 10 for oos generation\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n"
      ],
      "metadata": {
        "id": "OwnR2juv_U4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, _), (x_test, _) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Define the autoencoder architecture\n",
        "input_img = Input(shape=(32, 32, 3))\n",
        "\n",
        "# Encoder\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same', name='encoder_output')(x)\n",
        "\n",
        "# Decoder\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Create the autoencoder model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Create a model to output the encoder layer\n",
        "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('encoder_output').output)\n",
        "\n",
        "# Create a model to output the decoder layer\n",
        "decoder_input = Input(shape=(8, 8, 16), name='decoder_input')\n",
        "x = autoencoder.layers[-5](decoder_input)\n",
        "x = autoencoder.layers[-4](x)\n",
        "x = autoencoder.layers[-3](x)\n",
        "x = autoencoder.layers[-2](x)\n",
        "x = autoencoder.layers[-1](x)\n",
        "decoder_output = x\n",
        "decoder = Model(inputs=decoder_input, outputs=decoder_output, name='decoder')\n",
        "\n",
        "# Compile the model\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "AJ1s7VqPhplW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the autoencoder\n",
        "autoencoder.fit(x_train, x_train, epochs=10, batch_size=256, shuffle=True, validation_data=(x_test, x_test))"
      ],
      "metadata": {
        "id": "oqO6LpFPnKbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.save('/content/drive/MyDrive/ECE720/CIFAR_AE/encoder')\n",
        "decoder.save('/content/drive/MyDrive/ECE720/CIFAR_AE/decoder')"
      ],
      "metadata": {
        "id": "hP3PNFAFjUNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Step"
      ],
      "metadata": {
        "id": "-iKT2RV0_jJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mixup images"
      ],
      "metadata": {
        "id": "MXIGp_h54Fmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_image_pieces(im1, im2, im3, im4):\n",
        "    # Convert the images to NumPy arrays\n",
        "    arr1 = np.array(im1)\n",
        "    arr2 = np.array(im2)\n",
        "    arr3 = np.array(im3)\n",
        "    arr4 = np.array(im4)\n",
        "\n",
        "    # Split each image into four pieces\n",
        "    h, w, _ = arr1.shape\n",
        "    arr1_pieces = [arr1[:h//2, :w//2], arr1[:h//2, w//2:], arr1[h//2:, :w//2], arr1[h//2:, w//2:]]\n",
        "    arr2_pieces = [arr2[:h//2, :w//2], arr2[:h//2, w//2:], arr2[h//2:, :w//2], arr2[h//2:, w//2:]]\n",
        "    arr3_pieces = [arr3[:h//2, :w//2], arr3[:h//2, w//2:], arr3[h//2:, :w//2], arr3[h//2:, w//2:]]\n",
        "    arr4_pieces = [arr4[:h//2, :w//2], arr4[:h//2, w//2:], arr4[h//2:, :w//2], arr4[h//2:, w//2:]]\n",
        "\n",
        "    # Randomly shuffle the pieces\n",
        "    np.random.shuffle(arr1_pieces)\n",
        "    np.random.shuffle(arr2_pieces)\n",
        "    np.random.shuffle(arr3_pieces)\n",
        "    np.random.shuffle(arr4_pieces)\n",
        "    np.array(np.concatenate((arr1_pieces[0], arr2_pieces[1]),axis=0))\n",
        "\n",
        "    # Concatenate the shuffled pieces to create new images\n",
        "    arr_new1 = np.concatenate(\n",
        "        (np.concatenate((arr1_pieces[0], arr2_pieces[1]),axis=0), \n",
        "         np.concatenate((arr3_pieces[2], arr4_pieces[3]), axis=0)),\n",
        "     axis=1)\n",
        "    \n",
        "    arr_new2 = np.concatenate((\n",
        "        np.concatenate((arr2_pieces[0], arr3_pieces[1]),axis=0),\n",
        "        np.concatenate((arr4_pieces[2], arr1_pieces[3]), axis=0)),\n",
        "        axis=1)\n",
        "    \n",
        "    arr_new3 = np.concatenate((\n",
        "        np.concatenate((arr3_pieces[0], arr4_pieces[1]),axis=0),\n",
        "        np.concatenate((arr1_pieces[2], arr2_pieces[3]), axis=0)),\n",
        "        axis=1)\n",
        "    \n",
        "    arr_new4 = np.concatenate((\n",
        "        np.concatenate((arr4_pieces[0], arr1_pieces[1]),axis=0),\n",
        "        np.concatenate((arr2_pieces[2], arr3_pieces[3]), axis=0)),\n",
        "        axis=1)                             \n",
        "                               \n",
        "    # Return the new images\n",
        "    return arr_new1, arr_new2, arr_new3, arr_new4"
      ],
      "metadata": {
        "id": "fwkxvWBp4DAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, _), (x_test, _) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "T_lSRwOW5WRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_shuffled = []\n",
        "train_labels_shuffled = []\n",
        "for i in range(1400):\n",
        "  number_of_images = 4\n",
        "  # Randomly select 100 elements from the array\n",
        "  random_selection1 = x_train[np.random.choice(x_train.shape[0], size=number_of_images, replace=False)]\n",
        "  new_im1, new_im2, new_im3, new_im4 = shuffle_image_pieces(random_selection1[0],\n",
        "                       random_selection1[1],\n",
        "                       random_selection1[2],\n",
        "                       random_selection1[3])\n",
        "  \n",
        "  shuffled = [new_im1, new_im2, new_im3, new_im4]\n",
        "\n",
        "  train_images_shuffled = train_images_shuffled + shuffled\n",
        "  train_labels_shuffled = train_labels_shuffled + [[10],[10],[10],[10]]\n",
        "\n",
        "  # plt.figure(figsize=(10, 4))\n",
        "  # for i in range(4):\n",
        "  #     # Original image\n",
        "  #     plt.subplot(2, 4, i + 1)\n",
        "  #     plt.imshow(random_selection1[i])\n",
        "  #     plt.axis('off')\n",
        "\n",
        "      \n",
        "  #     # Encoded image\n",
        "  #     plt.subplot(2, 4, i + 5)\n",
        "  #     plt.imshow(shuffled[i])\n",
        "  #     plt.axis('off')\n",
        "\n",
        "  # plt.show()\n",
        "\n",
        "train_labels_shuffled = np.asarray(train_labels_shuffled)\n",
        "train_images_shuffled = np.asarray(train_images_shuffled).astype('float32') / 255."
      ],
      "metadata": {
        "id": "-HURd4w44LMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## USE AE"
      ],
      "metadata": {
        "id": "5KZMBpuW_zPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "encoder = tf.keras.models.load_model('/content/drive/MyDrive/ECE720/CIFAR_AE/encoder')\n",
        "decoder = tf.keras.models.load_model('/content/drive/MyDrive/ECE720/CIFAR_AE/decoder')\n",
        "\n",
        "\n",
        "# Plot the encoder output for the first 10 test images\n",
        "number_of_images = 8000\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, _), (x_test, _) = cifar10.load_data()\n",
        "# Randomly select 100 elements from the array\n",
        "random_selection1 = x_train[np.random.choice(x_train.shape[0], size=number_of_images, replace=False)].astype('float32') / 255.\n",
        "random_selection2 = x_train[np.random.choice(x_train.shape[0], size=number_of_images, replace=False)].astype('float32') / 255.\n",
        "\n",
        "encoded_imgs = encoder.predict((random_selection1 + random_selection2)/2)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)\n",
        "# decoded_imgs = autoencoder.predict(x_test[:10])\n",
        "# plt.figure(figsize=(20, 4))\n",
        "# for i in range(10):\n",
        "#     # Original image\n",
        "#     plt.subplot(2, 10, i + 1)\n",
        "#     plt.imshow(x_test[i])\n",
        "#     plt.axis('off')\n",
        "\n",
        "    \n",
        "#     # Encoded image\n",
        "#     plt.subplot(2, 10, i + 11)\n",
        "#     plt.imshow(decoded_imgs[i])\n",
        "#     plt.axis('off')\n",
        "\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FliHh_6Dp5s7",
        "outputId": "bc9e0e4f-2e3d-4801-812a-9b0162d9eeca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 [==============================] - 0s 2ms/step\n",
            "250/250 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load images from cifar100 and add as oos"
      ],
      "metadata": {
        "id": "nD6MIJEv_153"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names_cifar100 = [\n",
        "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle',\n",
        "    'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle',\n",
        "    'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup',\n",
        "    'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house',\n",
        "    'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man',\n",
        "    'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid',\n",
        "    'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy',\n",
        "    'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea',\n",
        "    'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel',\n",
        "    'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor',\n",
        "    'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
        "    'worm'\n",
        "]\n",
        "\n",
        "count_oos = 500\n",
        "\n",
        "\n",
        "# Load the CIFAR-10 and CIFAR-100 datasets\n",
        "(_, _), (x_cifar10, y_cifar10) = cifar10.load_data()\n",
        "(_, _), (x_cifar100, y_cifar100) = cifar100.load_data()\n",
        "\n",
        "# Define the CIFAR-10 and CIFAR-100 class dictionaries\n",
        "cifar10_classes = {\n",
        "    0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer',\n",
        "    5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'\n",
        "}\n",
        "\n",
        "cifar100_classes = {\n",
        "    i: class_name for i, class_name in enumerate(class_names_cifar100)\n",
        "}\n",
        "\n",
        "# Get the list of classes that are unique to CIFAR-100\n",
        "cifar100_unique_classes = set(cifar100_classes.values()) - set(cifar10_classes.values())\n",
        "\n",
        "cifar100_unique_classes_keys = []\n",
        "for key, value in cifar100_classes.items():\n",
        "  if value in cifar100_unique_classes:\n",
        "    cifar100_unique_classes_keys.append(key)\n",
        "\n",
        "# Select n random images from CIFAR-100 that belong to the unique classes\n",
        "indices = np.where(np.isin(y_cifar100, cifar100_unique_classes_keys))[0]\n",
        "selected_indices = np.random.choice(indices, size=count_oos, replace=False)\n",
        "x_selected_oos = x_cifar100[selected_indices].astype('float32') / 255.\n",
        "y_selected_oos = y_cifar100[selected_indices]\n",
        "\n",
        "# # Print the class labels of the selected images\n",
        "# for label in y_selected_oos:\n",
        "#     print(cifar100_classes[label[0]])\n",
        "\n",
        "\n",
        "y_selected_oos.fill(10)\n",
        "y_selected_oos_changed = np.random.randint(0, 10, size=(count_oos,1))"
      ],
      "metadata": {
        "id": "i6CPVGEYxzsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1c682df-fc96-4cd8-b701-a64d37d603e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 13s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final data prepration"
      ],
      "metadata": {
        "id": "w36u8bGMsNhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.astype('float32') / 255.\n",
        "\n",
        "train_labels_changed = copy.deepcopy(train_labels)\n",
        "\n",
        "# Select 100 random images\n",
        "random_indices = np.random.choice(train_labels_changed.shape[0], size=200, replace=False)\n",
        "\n",
        "# Flip the labels of the selected images\n",
        "train_labels_changed[random_indices] = np.random.randint(0, 10, size=(200,1))"
      ],
      "metadata": {
        "id": "LmH7ONlEAwLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # base without oos class\n",
        "# x_all = np.concatenate([x_selected_oos, train_images], axis=0)\n",
        "# y_all_changed = np.concatenate([y_selected_oos_changed, train_labels_changed], axis=0)\n",
        "# y_all = np.concatenate([y_selected_oos, train_labels], axis=0)"
      ],
      "metadata": {
        "id": "vZKICnlesRIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # base with oos class\n",
        "# x_all = np.concatenate([x_selected_oos, train_images, decoded_imgs, train_images_shuffled], axis=0)\n",
        "# y_all_changed = np.concatenate([y_selected_oos_changed, \n",
        "#                                 train_labels_changed, \n",
        "#                                 np.full((len(decoded_imgs), 1), 10),\n",
        "#                                 train_labels_shuffled], \n",
        "#                                 axis=0)\n",
        "# y_all = np.concatenate([y_selected_oos, \n",
        "#                         train_labels, \n",
        "#                         np.full((len(decoded_imgs), 1), 10),\n",
        "#                         train_labels_shuffled], \n",
        "#                         axis=0)\n",
        "\n",
        "file_path = '/content/drive/MyDrive/ECE720/CIFAR_AE/Cifar_data/'\n",
        "# Load the arrays from file\n",
        "x_all_loaded = np.load(file_path + 'x_all.npy')\n",
        "y_all_loaded = np.load(file_path + 'y_all.npy')\n",
        "y_all_changed_loaded = np.load(file_path + 'y_all_changed.npy')\n",
        "\n",
        "# base with oos class\n",
        "x_all = np.concatenate([x_all_loaded, decoded_imgs, train_images_shuffled], axis=0)\n",
        "y_all_changed = np.concatenate([y_all_changed_loaded,\n",
        "                                np.full((len(decoded_imgs), 1), 10),\n",
        "                                train_labels_shuffled], \n",
        "                                axis=0)\n",
        "y_all = np.concatenate([y_all_loaded,\n",
        "                        np.full((len(decoded_imgs), 1), 10),\n",
        "                        train_labels_shuffled], \n",
        "                        axis=0)"
      ],
      "metadata": {
        "id": "0u6sBEPTzfDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "permutation = np.random.permutation(x_all.shape[0])\n",
        "x_all = x_all[permutation]\n",
        "y_all_changed = y_all_changed[permutation]\n",
        "y_all = y_all[permutation]"
      ],
      "metadata": {
        "id": "axyDsL0baAQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Classifier For Out of sample Prediction"
      ],
      "metadata": {
        "id": "iUW1Yxd2Mj4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Assuming the dataframe is named \"final_data\" and you want to divide it into 5 folds\n",
        "k = 5\n",
        "kf = KFold(n_splits=k)\n",
        "\n",
        "fold_indices = []\n",
        "for train_index, test_index in kf.split(x_all):\n",
        "    fold_indices.append((train_index, test_index))"
      ],
      "metadata": {
        "id": "TCzmxa7kSjzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predctions = [[]] * len(x_all)\n",
        "for i, (train_index, test_index) in enumerate(fold_indices):\n",
        "\n",
        "  train_data = x_all[train_index]\n",
        "  test_data = x_all[test_index]\n",
        "\n",
        "  train_label = y_all_changed[train_index]\n",
        "  test_label = y_all_changed[test_index]\n",
        "\n",
        "\n",
        "  num_classes = 11\n",
        "  y_train = keras.utils.to_categorical(train_label, num_classes)\n",
        "  y_test = keras.utils.to_categorical(test_label, num_classes)\n",
        "\n",
        "  x_train = train_data.astype('float32')\n",
        "  x_test = test_data.astype('float32')\n",
        "\n",
        "\n",
        "  # loading B0 pre-trained on ImageNet without final aka fiature extractor\n",
        "  model = enet.EfficientNetB0(include_top=False, input_shape=(32,32,3), pooling='avg', weights='imagenet')\n",
        "\n",
        "  # building 2 fully connected layer \n",
        "  x = model.output\n",
        "\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(0.7)(x)\n",
        "\n",
        "  x = Dense(512)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(swish_act)(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "\n",
        "  x = Dense(128)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(swish_act)(x)\n",
        "\n",
        "  # output layer\n",
        "  predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
        "  model_final = Model(inputs = model.input, outputs = predictions)\n",
        "\n",
        "\n",
        "  # model compilation\n",
        "  model_final.compile(loss='categorical_crossentropy',\n",
        "                optimizer=Adam(0.0001),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # mcp_save = ModelCheckpoint('EnetB0_CIFAR10_TL.h5', save_best_only=True, monitor='val_acc')\n",
        "  reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, verbose=1,)\n",
        "\n",
        "  #print(\"Training....\")\n",
        "  model_final.fit(x_train, y_train,\n",
        "                  batch_size=512,\n",
        "                  epochs=15,\n",
        "                  validation_data=(x_test, y_test),\n",
        "                  callbacks=[reduce_lr],\n",
        "                  shuffle=True,\n",
        "                  verbose=1)\n",
        "\n",
        "\n",
        "  pred_probs = model_final.predict(x_test)\n",
        "  for j in range(len(test_index)):\n",
        "    predctions[test_index[j]] = pred_probs[j]"
      ],
      "metadata": {
        "id": "yclPusiBURc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = [np.argmax(i) for i in predctions]\n",
        "labels = y_all_changed"
      ],
      "metadata": {
        "id": "Th7uRfLzbT0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score"
      ],
      "metadata": {
        "id": "O2Ga8RuaCiPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm  = confusion_matrix(labels, preds)\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cm, figsize=(16,12), hide_ticks=True, cmap=plt.cm.Blues)\n",
        "plt.xticks(range(num_classes), list(range(num_classes)), fontsize=12)\n",
        "plt.yticks(range(num_classes),  list(range(num_classes)), fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W9H8puGAn-Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confident Learning Step"
      ],
      "metadata": {
        "id": "JS8-_mm6MypP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1 - Compute confident joint\n",
        "import cleanlab\n",
        "\n",
        "# Verify inputs\n",
        "labels = y_all_changed.reshape((1,-1))[0]\n",
        "pred_probs = np.asarray(predctions)\n",
        "\n",
        "# Find the number of unique classes if K is not given\n",
        "K = len(np.unique(labels))\n",
        "\n",
        "# Estimate the probability thresholds for confident counting\n",
        "# You can specify these thresholds yourself if you want\n",
        "# as you may want to optimize them using a validation set.\n",
        "# By default (and provably so) they are set to the average class prob.\n",
        "thresholds = [np.mean(pred_probs[:, k][labels == k]) for k in range(K)]  # P(label^=k|label=k)\n",
        "thresholds = np.asarray(thresholds)\n",
        "\n",
        "# Compute confident joint\n",
        "confident_joint = np.zeros((K, K), dtype=int)\n",
        "for i, row in enumerate(pred_probs):\n",
        "    # row = np.array(row)\n",
        "    s_label = labels[i]\n",
        "    # Find out how many classes each example is confidently labeled as\n",
        "    confident_bins = row >= thresholds - 1e-6\n",
        "    num_confident_bins = sum(confident_bins)\n",
        "    # If more than one conf class, inc the count of the max prob class\n",
        "    if num_confident_bins == 1:\n",
        "        confident_joint[s_label][np.argmax(confident_bins)] += 1\n",
        "    elif num_confident_bins > 1:\n",
        "        confident_joint[s_label][np.argmax(row)] += 1\n",
        "\n",
        "# Normalize confident joint (use cleanlab, trust me on this)\n",
        "confident_joint = cleanlab.count.calibrate_confident_joint(confident_joint, labels)\n",
        "\n",
        "cleanlab.internal.util.print_joint_matrix(confident_joint)\n"
      ],
      "metadata": {
        "id": "Nm-MLctmb-Fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2 - Find label errors\n",
        "\n",
        "# We arbitrarily choose at least 5 examples left in every class.\n",
        "# Regardless of whether some of them might be label errors.\n",
        "MIN_NUM_PER_CLASS = 5\n",
        "# Leave at least MIN_NUM_PER_CLASS examples per class.\n",
        "# NOTE prune_count_matrix is transposed (relative to confident_joint)\n",
        "prune_count_matrix = cleanlab.filter._keep_at_least_n_per_class(\n",
        "    prune_count_matrix=confident_joint.T,\n",
        "    n=MIN_NUM_PER_CLASS,\n",
        ")\n",
        "\n",
        "s_counts = np.bincount(labels)\n",
        "noise_masks_per_class = []\n",
        "# For each row in the transposed confident joint\n",
        "for k in range(K):\n",
        "    noise_mask = np.zeros(len(pred_probs), dtype=bool)\n",
        "    pred_probs_k = pred_probs[:, k]\n",
        "    if s_counts[k] > MIN_NUM_PER_CLASS:  # Don't prune if not MIN_NUM_PER_CLASS\n",
        "        for j in range(K):  # noisy label index (k is the true label index)\n",
        "            if k != j:  # Only prune for noise rates, not diagonal entries\n",
        "                num2prune = prune_count_matrix[k][j]\n",
        "                if num2prune > 0:\n",
        "                    # num2prune'th largest p(classk) - p(class j)\n",
        "                    # for x with noisy label j\n",
        "                    margin = pred_probs_k - pred_probs[:, j]\n",
        "                    s_filter = labels == j\n",
        "                    threshold = -np.partition(-margin[s_filter], num2prune - 1)[\n",
        "                        num2prune - 1\n",
        "                    ]\n",
        "                    noise_mask = noise_mask | (s_filter & (margin >= threshold))\n",
        "        noise_masks_per_class.append(noise_mask)\n",
        "    else:\n",
        "        noise_masks_per_class.append(np.zeros(len(labels), dtype=bool))\n",
        "\n",
        "# Boolean label error mask\n",
        "label_errors_bool = np.stack(noise_masks_per_class).any(axis=0)\n",
        "\n",
        "# Remove label errors if given label == model prediction\n",
        "for i, pred_label in enumerate(pred_probs.argmax(axis=1)):\n",
        "    # np.all lets this work for multi_label and single label\n",
        "    if label_errors_bool[i] and np.all(pred_label == labels[i]):\n",
        "        label_errors_bool[i] = False\n",
        "\n",
        "# Convert boolean mask to an ordered list of indices for label errors\n",
        "label_errors_idx = np.arange(len(labels))[label_errors_bool]\n",
        "# self confidence is the holdout probability that an example\n",
        "# belongs to its given class label\n",
        "self_confidence = np.array([np.mean(pred_probs[i][labels[i]]) for i in label_errors_idx])\n",
        "margin = self_confidence - pred_probs[label_errors_bool].max(axis=1)\n",
        "label_errors_idx = label_errors_idx[np.argsort(margin)]\n",
        "\n",
        "print(\"Indices of label errors found by confident learning:\")\n",
        "print(\"Note label errors are sorted by likelihood of being an error\")\n",
        "print(\"but here we just sort them by index for comparison with above.\")\n",
        "print(np.array(sorted(label_errors_idx)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqXE5bc6j_JQ",
        "outputId": "98513477-dd89-479b-c2c7-27fd4d88f881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indices of label errors found by confident learning:\n",
            "Note label errors are sorted by likelihood of being an error\n",
            "but here we just sort them by index for comparison with above.\n",
            "[    0     1     2 ... 66597 66598 66599]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_differences(arr1, arr2):\n",
        "    \"\"\"Returns the indexes where the values in the two arrays differ\"\"\"\n",
        "    diffs = []\n",
        "    for i in range(len(arr1)):\n",
        "        if arr1[i] != arr2[i]:\n",
        "            diffs.append(i)\n",
        "    return diffs\n",
        "\n",
        "actual_label_errors = find_differences(y_all,y_all_changed)\n",
        "NUM_ERRORS= len(actual_label_errors)\n",
        "NUM_ERRORS"
      ],
      "metadata": {
        "id": "vUaGkY6QlWB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_errors_idx_pruned = []\n",
        "for index in label_errors_idx:\n",
        "  if y_all[index] !=10 and y_all_changed[index] !=10:\n",
        "    label_errors_idx_pruned.append(index)\n"
      ],
      "metadata": {
        "id": "c96lzjnmLj6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = (sum([e in label_errors_idx for e in actual_label_errors]) / NUM_ERRORS) \n",
        "print(\"% actual errors that confident learning found: {:.0%}\".format(score))\n",
        "# score = sum([e in actual_label_errors for e in label_errors_idx]) / len(label_errors_idx)"
      ],
      "metadata": {
        "id": "aQjqpxM6jtnc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}